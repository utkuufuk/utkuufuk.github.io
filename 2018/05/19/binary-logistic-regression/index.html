<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/fav.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/fav.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/fav.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="5vPHUo26Cu0m53rV_72s-HEXqUFOM-Wcc-eI-CrKntk">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Inter:300,300italic,400,400italic,700,700italic|Roboto Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"utkuufuk.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"always","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":false,"async":true,"transition":{"post_header":"slideDownIn","post_body":"slideDownIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Logistic regression is a simple classification method which is widely used in the field of machine learning. Today we’re going to talk about how to train our own logistic regression model in Python to">
<meta property="og:type" content="article">
<meta property="og:title" content="Training a Simple Binary Classifier Using Logistic Regression">
<meta property="og:url" content="https://utkuufuk.com/2018/05/19/binary-logistic-regression/">
<meta property="og:site_name" content="Utku&#39;s Blog">
<meta property="og:description" content="Logistic regression is a simple classification method which is widely used in the field of machine learning. Today we’re going to talk about how to train our own logistic regression model in Python to">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://utkuufuk.com/2018/05/19/binary-logistic-regression/logistic-regression_5_0.png">
<meta property="og:image" content="https://utkuufuk.com/2018/05/19/binary-logistic-regression/sigmoid.png">
<meta property="og:image" content="https://utkuufuk.com/2018/05/19/binary-logistic-regression/cost.svg">
<meta property="og:image" content="https://utkuufuk.com/2018/05/19/binary-logistic-regression/logistic-regression_13_0.png">
<meta property="article:published_time" content="2018-05-19T12:49:51.000Z">
<meta property="article:modified_time" content="2025-02-11T09:13:35.281Z">
<meta property="article:author" content="Utku Ufuk">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://utkuufuk.com/2018/05/19/binary-logistic-regression/logistic-regression_5_0.png">

<link rel="canonical" href="https://utkuufuk.com/2018/05/19/binary-logistic-regression/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Training a Simple Binary Classifier Using Logistic Regression | Utku's Blog</title>
  
    <script>
      function sendPageView() {
        if (CONFIG.hostname !== location.hostname) return;
        var uid = localStorage.getItem('uid') || (Math.random() + '.' + Math.random());
        localStorage.setItem('uid', uid);
        navigator.sendBeacon('https://www.google-analytics.com/collect', new URLSearchParams({
          v  : 1,
          tid: 'UA-117512202-1',
          cid: uid,
          t  : 'pageview',
          dp : encodeURIComponent(location.pathname)
        }));
      }
      document.addEventListener('pjax:complete', sendPageView);
      sendPageView();
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Utku's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Utku's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-subscribe">

    <a href="/subscribe" rel="section"><i class="fas fa-bell fa-fw"></i>Subscribe</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fas fa-rss fa-fw"></i>RSS</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://utkuufuk.com/2018/05/19/binary-logistic-regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Utku Ufuk">
      <meta itemprop="description" content="Software Engineer">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Utku's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Training a Simple Binary Classifier Using Logistic Regression
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-05-19 15:49:51" itemprop="dateCreated datePublished" datetime="2018-05-19T15:49:51+03:00">2018-05-19</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Logistic regression is a simple classification method which is widely used in the field of machine learning. Today we’re going to talk about how to train our own logistic regression model in Python to build a a binary classifier. We’ll use <a target="_blank" rel="noopener" href="http://www.numpy.org/">NumPy</a> for matrix operations, <a target="_blank" rel="noopener" href="https://www.scipy.org/">SciPy</a> for cost minimization, <a target="_blank" rel="noopener" href="https://matplotlib.org/">Matplotlib</a> for data visualization and no machine learning tools or libraries whatsoever.</p>
<a id="more"></a>

<h4 id="Problem-amp-Dataset"><a href="#Problem-amp-Dataset" class="headerlink" title="Problem &amp; Dataset"></a>Problem &amp; Dataset</h4><p>We’ll be looking at another assignment from the <a target="_blank" rel="noopener" href="https://www.coursera.org/learn/machine-learning">machine learning course</a> taught by <a target="_blank" rel="noopener" href="http://www.andrewng.org/">Andrew Ng</a>. Our objective in this problem is to estimate an applicant’s probability of admission into a university based on his/her results on two exams. Our <a href="/2018/05/19/binary-logistic-regression/university_admission.txt" title="dataset">dataset</a> contains some historical data from previous applicants, which we’ll use as a training sample. Let’s read the dataset file and take a look at the first few examples:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> scipy.optimize <span class="keyword">as</span> opt</span><br><span class="line"></span><br><span class="line">data = np.loadtxt(<span class="string">&#x27;university_admission.txt&#x27;</span>, delimiter=<span class="string">&quot;,&quot;</span>)</span><br><span class="line">x = data[:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">y = data[:, <span class="number">2</span>]</span><br><span class="line">print(data[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<pre><code>[[ 34.62365962  78.02469282   0.        ]
 [ 30.28671077  43.89499752   0.        ]
 [ 35.84740877  72.90219803   0.        ]
 [ 60.18259939  86.3085521    1.        ]
 [ 79.03273605  75.34437644   1.        ]]</code></pre>
<p>The first two columns correspond to the exam scores and the third column indicates whether the applicant has been admitted to the university. We can visualize this data using a scatter plot:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">positives = np.where(y == <span class="number">1</span>)</span><br><span class="line">negatives = np.where(y == <span class="number">0</span>)</span><br><span class="line">ax.scatter(x[positives, <span class="number">0</span>], x[positives, <span class="number">1</span>], marker=<span class="string">&quot;+&quot;</span>, c=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">ax.scatter(x[negatives, <span class="number">0</span>], x[negatives, <span class="number">1</span>], marker=<span class="string">&quot;x&quot;</span>, c=<span class="string">&#x27;red&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.title(<span class="string">&quot;University Admission&quot;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;exam 1 score&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;exam 2 score&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;admitted&quot;</span>, <span class="string">&quot;not admitted&quot;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src="/2018/05/19/binary-logistic-regression/logistic-regression_5_0.png" class="">

<h4 id="Hypothesis-Function"><a href="#Hypothesis-Function" class="headerlink" title="Hypothesis Function"></a>Hypothesis Function</h4><p>Logistic regression is a linear model, which means that the <strong>decision boundary</strong> has to be a straight line. This can be achieved with a a simple hypothesis function in the following form:</p>
<p>$h_\theta(x) = g(\theta^Tx)$</p>
<p>where $g$ is the <strong>sigmoid function</strong> which is defined as:</p>
<p>$g(z) = \dfrac{1}{1 + e^{-z}}$</p>
<img src="/2018/05/19/binary-logistic-regression/sigmoid.png" class="" title="Sigmoid">
<br>

<p>Here’s the Python version of the sigmoid function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">z</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br></pre></td></tr></table></figure>
<p>The numeric output of the hypothesis function $h_\theta(x)$ corresponds to the model’s confidence in labeling the input:</p>
<ul>
<li>If the output is $0.5$, both classes are equally probable as far as the classifier is concerned.</li>
<li>If the output is $1$, the classifier is 100% confident about class 1.</li>
<li>If the output is $0$, the classifier is 100% confident about class 0.</li>
</ul>
<p>In other words, the classifier labels the input based on whether $\theta^Tx$ is positive or negative. Of course this is based on the assumption that the treshold is selected as $0.5$.</p>
<h4 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h4><p>In the training stage, we’ll try to minimize the cost function below:</p>
<p>$J(\theta) = \dfrac{1}{m}\sum\limits_{i=1}^{m}[-y^{(i)}log(h_\theta(x^{(i)})) - (1 - y^{(i)})log(1 - h_\theta(x^{(i)}))]$</p>
<p>Notice that this cost function penalizes the hypothesis according to its probability estimation error, as demonstrated below:</p>
<img src="/2018/05/19/binary-logistic-regression/cost.svg" class="" title="Cost">
<p>&lt;br &gt;</p>
<p>We can use the following Python function to compute this cost in our script:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span>(<span class="params">theta, X, y</span>):</span></span><br><span class="line">    predictions = sigmoid(X @ theta)</span><br><span class="line">    predictions[predictions == <span class="number">1</span>] = <span class="number">0.999</span> <span class="comment"># log(1)=0 causes division error during optimization</span></span><br><span class="line">    error = -y * np.log(predictions) - (<span class="number">1</span> - y) * np.log(<span class="number">1</span> - predictions);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(error) / <span class="built_in">len</span>(y);</span><br></pre></td></tr></table></figure>
<h4 id="Optimization-Algorithm"><a href="#Optimization-Algorithm" class="headerlink" title="Optimization Algorithm"></a>Optimization Algorithm</h4><p>We’re going to use the <strong><code>fmin_cg</code></strong> function from <strong><code>scipy.optimize</code></strong> to minimize our cost. <strong><code>fmin_cg</code></strong> needs the gradient of the cost function as well as the cost function itself. Here’s the formula for the cost gradient:</p>
<p>$\dfrac{\partial{J(\theta)}}{\partial{\theta_j}} = \dfrac{1}{m}\sum\limits_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})x^{(i)}_j$</p>
<p>where $m$ is the number of training examples.</p>
<p>And the Python version is:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost_gradient</span>(<span class="params">theta, X, y</span>):</span></span><br><span class="line">    predictions = sigmoid(X @ theta);</span><br><span class="line">    <span class="keyword">return</span> X.transpose() @ (predictions - y) / <span class="built_in">len</span>(y)</span><br></pre></td></tr></table></figure>
<p>If you’re not familiar with <strong><code>fmin_cg</code></strong>, it might be a good idea to check out my <a href="/2018/05/04/learning-curves/" title="previous post">previous post</a> and/or the <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.fmin_cg.html">official docs</a> before proceeding to the next section.</p>
<h4 id="Training-Stage"><a href="#Training-Stage" class="headerlink" title="Training Stage"></a>Training Stage</h4><p>The final thing we need to do before training our model is to add an additional first column to $x$, in order to account for the intercept term $\theta_0$:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = np.ones(shape=(x.shape[<span class="number">0</span>], x.shape[<span class="number">1</span>] + <span class="number">1</span>))</span><br><span class="line">X[:, <span class="number">1</span>:] = x</span><br></pre></td></tr></table></figure>
<p>Finally we can train our logistic regression model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">initial_theta = np.zeros(X.shape[<span class="number">1</span>]) <span class="comment"># set initial model parameters to zero</span></span><br><span class="line">theta = opt.fmin_cg(cost, initial_theta, cost_gradient, (X, y))</span><br></pre></td></tr></table></figure>
<pre><code>Optimization terminated successfully.
         Current function value: 0.203498
         Iterations: 51
         Function evaluations: 122
         Gradient evaluations: 122</code></pre>
<p>Now let’s plot the decision boundary of our optimized model:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_axis = np.array([<span class="built_in">min</span>(X[:, <span class="number">1</span>]) - <span class="number">2</span>, <span class="built_in">max</span>(X[:, <span class="number">1</span>]) + <span class="number">2</span>])</span><br><span class="line">y_axis = (-<span class="number">1</span> / theta[<span class="number">2</span>]) * (theta[<span class="number">1</span>] * x_axis + theta[<span class="number">0</span>])</span><br><span class="line">ax.plot(x_axis, y_axis, linewidth=<span class="number">2</span>)</span><br><span class="line">fig</span><br></pre></td></tr></table></figure>
<img src="/2018/05/19/binary-logistic-regression/logistic-regression_13_0.png" class="">
<br>
Looks pretty good. Let's also measure the training accuracy:

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">predictions = np.zeros(<span class="built_in">len</span>(y))</span><br><span class="line">predictions[sigmoid(X @ theta) &gt;= <span class="number">0.5</span>] = <span class="number">1</span></span><br><span class="line">print(<span class="string">&quot;Training Accuracy =&quot;</span>, <span class="built_in">str</span>(np.mean(predictions == y) * <span class="number">100</span>) + <span class="string">&quot;%&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Training Accuracy = 89.0%</code></pre>
<p>Not bad at all. We would probably need something little more flexible than logistic regression if we wanted to come up with a more accurate classifier.</p>
<h4 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h4><p>Finally, here’s how we can predict the probability of admission for a student with arbitrary exam scores:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">probability = sigmoid(np.array([<span class="number">1</span>, <span class="number">45</span>, <span class="number">85</span>]) @ theta)</span><br><span class="line">print(<span class="string">&quot;For a student with scores 45 and 85, we predict an admission probability of&quot;</span>, probability)</span><br></pre></td></tr></table></figure>
<pre><code>For a student with scores 45 and 85, we predict an admission probability of 0.776195474168</code></pre>
<p>If you’re still here, you should <a href="%5Csubscribe">subscribe</a> to get updates on my future articles.</p>

    </div>

    
    
    
        

  <div class="followme">
    <p>Follow me on</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://github.com/utkuufuk">
            <span class="icon">
              <i class="fab fa-github"></i>
            </span>

            <span class="label">GitHub</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://twitter.com/utkufu">
            <span class="icon">
              <i class="fab fa-twitter"></i>
            </span>

            <span class="label">Twitter</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="https://youtube.com/utkuufuk">
            <span class="icon">
              <i class="fab fa-youtube"></i>
            </span>

            <span class="label">YouTube</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/subscribe">
            <span class="icon">
              <i class="fas fa-bell"></i>
            </span>

            <span class="label">Subscribe</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a>
              <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
              <a href="/tags/AI/" rel="tag"><i class="fa fa-tag"></i> AI</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/05/04/learning-curves/" rel="prev" title="Learning Curves in Linear & Polynomial Regression">
      <i class="fa fa-chevron-left"></i> Learning Curves in Linear & Polynomial Regression
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/06/03/one-vs-all-classification/" rel="next" title="One-vs-All Classification Using Logistic Regression">
      One-vs-All Classification Using Logistic Regression <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#Problem-amp-Dataset"><span class="nav-number">1.</span> <span class="nav-text">Problem &amp; Dataset</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Hypothesis-Function"><span class="nav-number">2.</span> <span class="nav-text">Hypothesis Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cost-Function"><span class="nav-number">3.</span> <span class="nav-text">Cost Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Optimization-Algorithm"><span class="nav-number">4.</span> <span class="nav-text">Optimization Algorithm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-Stage"><span class="nav-number">5.</span> <span class="nav-text">Training Stage</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Prediction"><span class="nav-number">6.</span> <span class="nav-text">Prediction</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Utku Ufuk"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Utku Ufuk</p>
  <div class="site-description" itemprop="description">Software Engineer</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">14</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/utkuufuk" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;utkuufuk" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/utkufu" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;utkufu" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://youtube.com/utkuufuk" title="YouTube → https:&#x2F;&#x2F;youtube.com&#x2F;utkuufuk" rel="noopener" target="_blank"><i class="fab fa-youtube fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://linkedin.com/in/utku-ufuk" title="LinkedIn → https:&#x2F;&#x2F;linkedin.com&#x2F;in&#x2F;utku-ufuk" rel="noopener" target="_blank"><i class="fab fa-linkedin fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:utkuufuk@gmail.com" title="E-Mail → mailto:utkuufuk@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="/atom.xml" title="&#x2F;atom.xml">RSS</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="/subscribe" title="&#x2F;subscribe">Subscribe</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Utku Ufuk</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
